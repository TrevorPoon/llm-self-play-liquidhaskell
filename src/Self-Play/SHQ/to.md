
livecodebench

utilize gpu for multi gen in multi gpus

eval_instruct result/adapter_path

last layer finetuning instead of LoRA

How to finetune reasoning model

pip install flashinfer-python